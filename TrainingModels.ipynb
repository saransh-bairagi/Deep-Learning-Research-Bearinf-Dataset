{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "456801d1-98a1-40d8-8c28-9a303aef08d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Libraries\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "\n",
    "# Splits\n",
    "\n",
    "#MODELS\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# MISC\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "970fc816-22ee-4241-bca5-1ca89723e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "cwd=os.getcwd()\n",
    "dpath=os.path.join(cwd,\"./MAJORDATASET.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "0ebc92ef-f3ac-49d9-b5e4-5fa6566ba5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(dpath)\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "942c0f55-8aac-44d6-afc1-7da6dc3397c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Outer Race', 'Inner Race', 'Normal', 'Roller Element'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(df['Fault'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "e69efe99-d6c2-45b1-92ed-094efde22fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>RMS</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Crest Factor</th>\n",
       "      <th>Form Factor</th>\n",
       "      <th>Fault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>0.654</td>\n",
       "      <td>-0.706</td>\n",
       "      <td>-0.001451</td>\n",
       "      <td>0.150926</td>\n",
       "      <td>0.150929</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>0.878273</td>\n",
       "      <td>4.333163</td>\n",
       "      <td>-104.004918</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>0.376</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.003689</td>\n",
       "      <td>0.086722</td>\n",
       "      <td>0.086799</td>\n",
       "      <td>-0.077486</td>\n",
       "      <td>0.164610</td>\n",
       "      <td>4.331860</td>\n",
       "      <td>-23.531477</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.557</td>\n",
       "      <td>-1.052</td>\n",
       "      <td>-0.115337</td>\n",
       "      <td>0.117592</td>\n",
       "      <td>0.164711</td>\n",
       "      <td>-0.053534</td>\n",
       "      <td>1.106944</td>\n",
       "      <td>3.381677</td>\n",
       "      <td>-1.428088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>0.371</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>0.073584</td>\n",
       "      <td>0.073602</td>\n",
       "      <td>-0.025459</td>\n",
       "      <td>0.370398</td>\n",
       "      <td>5.040625</td>\n",
       "      <td>-42.723444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.801</td>\n",
       "      <td>-1.113</td>\n",
       "      <td>-0.115291</td>\n",
       "      <td>0.143753</td>\n",
       "      <td>0.184271</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>2.015149</td>\n",
       "      <td>4.346853</td>\n",
       "      <td>-1.598314</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Max    Min      Mean       Std       RMS  Skewness  Kurtosis  \\\n",
       "1428  0.654 -0.706 -0.001451  0.150926  0.150929  0.006866  0.878273   \n",
       "1587  0.376 -0.400 -0.003689  0.086722  0.086799 -0.077486  0.164610   \n",
       "38    0.557 -1.052 -0.115337  0.117592  0.164711 -0.053534  1.106944   \n",
       "846   0.371 -0.366 -0.001723  0.073584  0.073602 -0.025459  0.370398   \n",
       "2009  0.801 -1.113 -0.115291  0.143753  0.184271 -0.000291  2.015149   \n",
       "\n",
       "      Crest Factor  Form Factor  Fault  \n",
       "1428      4.333163  -104.004918      2  \n",
       "1587      4.331860   -23.531477      2  \n",
       "38        3.381677    -1.428088      0  \n",
       "846       5.040625   -42.723444      1  \n",
       "2009      4.346853    -1.598314      3  "
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Fault'] = df['Fault'].map({'Inner Race':0, 'Normal':1,'Outer Race':2,'Roller Element':3})\n",
    "df=df.drop(df.columns[0],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "7d55a92f-3036-4da6-aa3a-99c4d1510b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>RMS</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Crest Factor</th>\n",
       "      <th>Form Factor</th>\n",
       "      <th>Fault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>0.654</td>\n",
       "      <td>-0.706</td>\n",
       "      <td>-0.001451</td>\n",
       "      <td>0.150926</td>\n",
       "      <td>0.150929</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>0.878273</td>\n",
       "      <td>4.333163</td>\n",
       "      <td>-104.004918</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>0.376</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.003689</td>\n",
       "      <td>0.086722</td>\n",
       "      <td>0.086799</td>\n",
       "      <td>-0.077486</td>\n",
       "      <td>0.164610</td>\n",
       "      <td>4.331860</td>\n",
       "      <td>-23.531477</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.557</td>\n",
       "      <td>-1.052</td>\n",
       "      <td>-0.115337</td>\n",
       "      <td>0.117592</td>\n",
       "      <td>0.164711</td>\n",
       "      <td>-0.053534</td>\n",
       "      <td>1.106944</td>\n",
       "      <td>3.381677</td>\n",
       "      <td>-1.428088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>0.371</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>0.073584</td>\n",
       "      <td>0.073602</td>\n",
       "      <td>-0.025459</td>\n",
       "      <td>0.370398</td>\n",
       "      <td>5.040625</td>\n",
       "      <td>-42.723444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.801</td>\n",
       "      <td>-1.113</td>\n",
       "      <td>-0.115291</td>\n",
       "      <td>0.143753</td>\n",
       "      <td>0.184271</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>2.015149</td>\n",
       "      <td>4.346853</td>\n",
       "      <td>-1.598314</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.642</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>-0.114168</td>\n",
       "      <td>0.116868</td>\n",
       "      <td>0.163376</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.724326</td>\n",
       "      <td>3.929584</td>\n",
       "      <td>-1.431014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>0.835</td>\n",
       "      <td>-0.864</td>\n",
       "      <td>-0.114424</td>\n",
       "      <td>0.138179</td>\n",
       "      <td>0.179402</td>\n",
       "      <td>0.034667</td>\n",
       "      <td>1.648927</td>\n",
       "      <td>4.654346</td>\n",
       "      <td>-1.567879</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>0.356</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>0.078904</td>\n",
       "      <td>0.078917</td>\n",
       "      <td>-0.017752</td>\n",
       "      <td>0.088891</td>\n",
       "      <td>4.511050</td>\n",
       "      <td>-50.445602</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.864</td>\n",
       "      <td>-2.454</td>\n",
       "      <td>-0.115784</td>\n",
       "      <td>0.119928</td>\n",
       "      <td>0.166697</td>\n",
       "      <td>-0.664912</td>\n",
       "      <td>13.750798</td>\n",
       "      <td>5.183052</td>\n",
       "      <td>-1.439727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>1.453</td>\n",
       "      <td>-1.333</td>\n",
       "      <td>-0.114960</td>\n",
       "      <td>0.139082</td>\n",
       "      <td>0.180440</td>\n",
       "      <td>-0.031761</td>\n",
       "      <td>8.637405</td>\n",
       "      <td>8.052534</td>\n",
       "      <td>-1.569589</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>1.042</td>\n",
       "      <td>-1.174</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>0.285856</td>\n",
       "      <td>0.285854</td>\n",
       "      <td>-0.155344</td>\n",
       "      <td>0.241043</td>\n",
       "      <td>3.645214</td>\n",
       "      <td>-170.455545</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>0.903</td>\n",
       "      <td>-0.662</td>\n",
       "      <td>-0.001862</td>\n",
       "      <td>0.120501</td>\n",
       "      <td>0.120512</td>\n",
       "      <td>-0.077874</td>\n",
       "      <td>1.835867</td>\n",
       "      <td>7.493023</td>\n",
       "      <td>-64.716361</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.361</td>\n",
       "      <td>-0.710</td>\n",
       "      <td>-0.115018</td>\n",
       "      <td>0.108955</td>\n",
       "      <td>0.158429</td>\n",
       "      <td>-0.000782</td>\n",
       "      <td>0.306672</td>\n",
       "      <td>2.278617</td>\n",
       "      <td>-1.377428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.564</td>\n",
       "      <td>-0.813</td>\n",
       "      <td>-0.114834</td>\n",
       "      <td>0.118422</td>\n",
       "      <td>0.164954</td>\n",
       "      <td>0.025798</td>\n",
       "      <td>0.551609</td>\n",
       "      <td>3.419127</td>\n",
       "      <td>-1.436454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.298</td>\n",
       "      <td>-0.305</td>\n",
       "      <td>-0.001284</td>\n",
       "      <td>0.069871</td>\n",
       "      <td>0.069881</td>\n",
       "      <td>-0.011671</td>\n",
       "      <td>0.107428</td>\n",
       "      <td>4.264401</td>\n",
       "      <td>-54.414665</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.369</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>-0.002567</td>\n",
       "      <td>0.075081</td>\n",
       "      <td>0.075123</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.615384</td>\n",
       "      <td>4.911913</td>\n",
       "      <td>-29.266846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>0.623</td>\n",
       "      <td>-0.676</td>\n",
       "      <td>-0.001564</td>\n",
       "      <td>0.156186</td>\n",
       "      <td>0.156190</td>\n",
       "      <td>-0.019371</td>\n",
       "      <td>0.225847</td>\n",
       "      <td>3.988720</td>\n",
       "      <td>-99.896334</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.576</td>\n",
       "      <td>-0.113746</td>\n",
       "      <td>0.081480</td>\n",
       "      <td>0.139917</td>\n",
       "      <td>-0.055039</td>\n",
       "      <td>1.329975</td>\n",
       "      <td>2.723039</td>\n",
       "      <td>-1.230082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>0.632</td>\n",
       "      <td>-0.862</td>\n",
       "      <td>-0.114187</td>\n",
       "      <td>0.137804</td>\n",
       "      <td>0.178963</td>\n",
       "      <td>0.024322</td>\n",
       "      <td>1.989022</td>\n",
       "      <td>3.531450</td>\n",
       "      <td>-1.567278</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.001842</td>\n",
       "      <td>0.081517</td>\n",
       "      <td>0.081536</td>\n",
       "      <td>0.185316</td>\n",
       "      <td>0.372620</td>\n",
       "      <td>6.671929</td>\n",
       "      <td>-44.259055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Max    Min      Mean       Std       RMS  Skewness   Kurtosis  \\\n",
       "1428  0.654 -0.706 -0.001451  0.150926  0.150929  0.006866   0.878273   \n",
       "1587  0.376 -0.400 -0.003689  0.086722  0.086799 -0.077486   0.164610   \n",
       "38    0.557 -1.052 -0.115337  0.117592  0.164711 -0.053534   1.106944   \n",
       "846   0.371 -0.366 -0.001723  0.073584  0.073602 -0.025459   0.370398   \n",
       "2009  0.801 -1.113 -0.115291  0.143753  0.184271 -0.000291   2.015149   \n",
       "52    0.642 -0.798 -0.114168  0.116868  0.163376  0.001800   0.724326   \n",
       "2109  0.835 -0.864 -0.114424  0.138179  0.179402  0.034667   1.648927   \n",
       "1542  0.356 -0.393 -0.001564  0.078904  0.078917 -0.017752   0.088891   \n",
       "209   0.864 -2.454 -0.115784  0.119928  0.166697 -0.664912  13.750798   \n",
       "1894  1.453 -1.333 -0.114960  0.139082  0.180440 -0.031761   8.637405   \n",
       "1774  1.042 -1.174 -0.001677  0.285856  0.285854 -0.155344   0.241043   \n",
       "1262  0.903 -0.662 -0.001862  0.120501  0.120512 -0.077874   1.835867   \n",
       "66    0.361 -0.710 -0.115018  0.108955  0.158429 -0.000782   0.306672   \n",
       "179   0.564 -0.813 -0.114834  0.118422  0.164954  0.025798   0.551609   \n",
       "1459  0.298 -0.305 -0.001284  0.069871  0.069881 -0.011671   0.107428   \n",
       "800   0.369 -0.464 -0.002567  0.075081  0.075123  0.002548   0.615384   \n",
       "1733  0.623 -0.676 -0.001564  0.156186  0.156190 -0.019371   0.225847   \n",
       "629   0.381 -0.576 -0.113746  0.081480  0.139917 -0.055039   1.329975   \n",
       "2156  0.632 -0.862 -0.114187  0.137804  0.178963  0.024322   1.989022   \n",
       "856   0.544 -0.393 -0.001842  0.081517  0.081536  0.185316   0.372620   \n",
       "\n",
       "      Crest Factor  Form Factor  Fault  \n",
       "1428      4.333163  -104.004918      2  \n",
       "1587      4.331860   -23.531477      2  \n",
       "38        3.381677    -1.428088      0  \n",
       "846       5.040625   -42.723444      1  \n",
       "2009      4.346853    -1.598314      3  \n",
       "52        3.929584    -1.431014      0  \n",
       "2109      4.654346    -1.567879      3  \n",
       "1542      4.511050   -50.445602      2  \n",
       "209       5.183052    -1.439727      0  \n",
       "1894      8.052534    -1.569589      3  \n",
       "1774      3.645214  -170.455545      2  \n",
       "1262      7.493023   -64.716361      2  \n",
       "66        2.278617    -1.377428      0  \n",
       "179       3.419127    -1.436454      0  \n",
       "1459      4.264401   -54.414665      2  \n",
       "800       4.911913   -29.266846      1  \n",
       "1733      3.988720   -99.896334      2  \n",
       "629       2.723039    -1.230082      1  \n",
       "2156      3.531450    -1.567278      3  \n",
       "856       6.671929   -44.259055      1  "
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "920c07e2-182e-4d70-b707-fe62a8b0dd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>RMS</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Crest Factor</th>\n",
       "      <th>Form Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>0.654</td>\n",
       "      <td>-0.706</td>\n",
       "      <td>-0.001451</td>\n",
       "      <td>0.150926</td>\n",
       "      <td>0.150929</td>\n",
       "      <td>0.006866</td>\n",
       "      <td>0.878273</td>\n",
       "      <td>4.333163</td>\n",
       "      <td>-104.004918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>0.376</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.003689</td>\n",
       "      <td>0.086722</td>\n",
       "      <td>0.086799</td>\n",
       "      <td>-0.077486</td>\n",
       "      <td>0.164610</td>\n",
       "      <td>4.331860</td>\n",
       "      <td>-23.531477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.557</td>\n",
       "      <td>-1.052</td>\n",
       "      <td>-0.115337</td>\n",
       "      <td>0.117592</td>\n",
       "      <td>0.164711</td>\n",
       "      <td>-0.053534</td>\n",
       "      <td>1.106944</td>\n",
       "      <td>3.381677</td>\n",
       "      <td>-1.428088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>0.371</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>0.073584</td>\n",
       "      <td>0.073602</td>\n",
       "      <td>-0.025459</td>\n",
       "      <td>0.370398</td>\n",
       "      <td>5.040625</td>\n",
       "      <td>-42.723444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.801</td>\n",
       "      <td>-1.113</td>\n",
       "      <td>-0.115291</td>\n",
       "      <td>0.143753</td>\n",
       "      <td>0.184271</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>2.015149</td>\n",
       "      <td>4.346853</td>\n",
       "      <td>-1.598314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Max    Min      Mean       Std       RMS  Skewness  Kurtosis  \\\n",
       "1428  0.654 -0.706 -0.001451  0.150926  0.150929  0.006866  0.878273   \n",
       "1587  0.376 -0.400 -0.003689  0.086722  0.086799 -0.077486  0.164610   \n",
       "38    0.557 -1.052 -0.115337  0.117592  0.164711 -0.053534  1.106944   \n",
       "846   0.371 -0.366 -0.001723  0.073584  0.073602 -0.025459  0.370398   \n",
       "2009  0.801 -1.113 -0.115291  0.143753  0.184271 -0.000291  2.015149   \n",
       "\n",
       "      Crest Factor  Form Factor  \n",
       "1428      4.333163  -104.004918  \n",
       "1587      4.331860   -23.531477  \n",
       "38        3.381677    -1.428088  \n",
       "846       5.040625   -42.723444  \n",
       "2009      4.346853    -1.598314  "
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,0:-1]\n",
    "y=df.iloc[:,-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2332436e-d39a-4288-9fd5-147bcb68d541",
   "metadata": {},
   "source": [
    "# Data Splitting and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "5f7dad94-7ea3-4c76-a101-f230b2099feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(456, 9)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object= StandardScaler()\n",
    "scale = object.fit_transform(df)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,)\n",
    "X_train_scaled=object.fit_transform(X_train)\n",
    "X_test_scaled=object.fit_transform(X_test)\n",
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda65524-6cfa-459f-8b93-0011581e0ba5",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "963786c6-9730-42ad-b25a-d2f192167cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "64/64 [==============================] - 1s 4ms/step - loss: 1.4188 - accuracy: 0.2910 - val_loss: 1.3248 - val_accuracy: 0.5430\n",
      "Epoch 2/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.3431 - accuracy: 0.3898 - val_loss: 1.2694 - val_accuracy: 0.5009\n",
      "Epoch 3/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.2699 - accuracy: 0.4118 - val_loss: 1.1517 - val_accuracy: 0.4753\n",
      "Epoch 4/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.2069 - accuracy: 0.4337 - val_loss: 1.0392 - val_accuracy: 0.5155\n",
      "Epoch 5/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.0970 - accuracy: 0.5137 - val_loss: 0.9207 - val_accuracy: 0.5539\n",
      "Epoch 6/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 1.0740 - accuracy: 0.5286 - val_loss: 0.8434 - val_accuracy: 0.6106\n",
      "Epoch 7/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.9925 - accuracy: 0.5412 - val_loss: 0.7876 - val_accuracy: 0.6746\n",
      "Epoch 8/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.9668 - accuracy: 0.5710 - val_loss: 0.7654 - val_accuracy: 0.6709\n",
      "Epoch 9/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.9435 - accuracy: 0.5529 - val_loss: 0.7531 - val_accuracy: 0.6453\n",
      "Epoch 10/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.8978 - accuracy: 0.5961 - val_loss: 0.7255 - val_accuracy: 0.6581\n",
      "Epoch 11/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.8558 - accuracy: 0.6016 - val_loss: 0.7018 - val_accuracy: 0.6636\n",
      "Epoch 12/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.8453 - accuracy: 0.5875 - val_loss: 0.6890 - val_accuracy: 0.7550\n",
      "Epoch 13/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.8553 - accuracy: 0.5976 - val_loss: 0.6881 - val_accuracy: 0.7038\n",
      "Epoch 14/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.8119 - accuracy: 0.6031 - val_loss: 0.6716 - val_accuracy: 0.6801\n",
      "Epoch 15/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.7856 - accuracy: 0.6282 - val_loss: 0.6489 - val_accuracy: 0.7715\n",
      "Epoch 16/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.7900 - accuracy: 0.6361 - val_loss: 0.6504 - val_accuracy: 0.6837\n",
      "Epoch 17/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.7778 - accuracy: 0.6565 - val_loss: 0.6240 - val_accuracy: 0.7331\n",
      "Epoch 18/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.7540 - accuracy: 0.6322 - val_loss: 0.6152 - val_accuracy: 0.7075\n",
      "Epoch 19/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.7709 - accuracy: 0.6557 - val_loss: 0.5981 - val_accuracy: 0.7697\n",
      "Epoch 20/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.7429 - accuracy: 0.6612 - val_loss: 0.5817 - val_accuracy: 0.7313\n",
      "Epoch 21/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.6925 - val_loss: 0.5637 - val_accuracy: 0.8117\n",
      "Epoch 22/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.6839 - val_loss: 0.5626 - val_accuracy: 0.7916\n",
      "Epoch 23/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6687 - accuracy: 0.7122 - val_loss: 0.5343 - val_accuracy: 0.7569\n",
      "Epoch 24/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.7059 - val_loss: 0.5267 - val_accuracy: 0.7514\n",
      "Epoch 25/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6957 - val_loss: 0.5142 - val_accuracy: 0.8044\n",
      "Epoch 26/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.7059 - val_loss: 0.5076 - val_accuracy: 0.7660\n",
      "Epoch 27/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.7043 - val_loss: 0.5011 - val_accuracy: 0.7697\n",
      "Epoch 28/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.6910 - val_loss: 0.4996 - val_accuracy: 0.7514\n",
      "Epoch 29/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.7027 - val_loss: 0.4858 - val_accuracy: 0.7550\n",
      "Epoch 30/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6077 - accuracy: 0.7153 - val_loss: 0.4849 - val_accuracy: 0.7441\n",
      "Epoch 31/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.7114 - val_loss: 0.4853 - val_accuracy: 0.7386\n",
      "Epoch 32/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.7106 - val_loss: 0.4727 - val_accuracy: 0.7605\n",
      "Epoch 33/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7169 - val_loss: 0.4787 - val_accuracy: 0.7313\n",
      "Epoch 34/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.7067 - val_loss: 0.4722 - val_accuracy: 0.7587\n",
      "Epoch 35/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7145 - val_loss: 0.4656 - val_accuracy: 0.7605\n",
      "Epoch 36/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7294 - val_loss: 0.4800 - val_accuracy: 0.7477\n",
      "Epoch 37/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7271 - val_loss: 0.4579 - val_accuracy: 0.7605\n",
      "Epoch 38/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.6910 - val_loss: 0.4637 - val_accuracy: 0.7514\n",
      "Epoch 39/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7059 - val_loss: 0.4534 - val_accuracy: 0.7642\n",
      "Epoch 40/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7247 - val_loss: 0.4602 - val_accuracy: 0.7514\n",
      "Epoch 41/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7216 - val_loss: 0.4539 - val_accuracy: 0.7623\n",
      "Epoch 42/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7302 - val_loss: 0.4544 - val_accuracy: 0.7203\n",
      "Epoch 43/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7412 - val_loss: 0.4649 - val_accuracy: 0.7057\n",
      "Epoch 44/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7192 - val_loss: 0.4500 - val_accuracy: 0.7660\n",
      "Epoch 45/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7302 - val_loss: 0.4564 - val_accuracy: 0.7569\n",
      "Epoch 46/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7357 - val_loss: 0.4619 - val_accuracy: 0.7130\n",
      "Epoch 47/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.7012 - val_loss: 0.4523 - val_accuracy: 0.7459\n",
      "Epoch 48/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7051 - val_loss: 0.4532 - val_accuracy: 0.7550\n",
      "Epoch 49/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7255 - val_loss: 0.4419 - val_accuracy: 0.7239\n",
      "Epoch 50/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7255 - val_loss: 0.4448 - val_accuracy: 0.7514\n",
      "Epoch 51/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7192 - val_loss: 0.4396 - val_accuracy: 0.7715\n",
      "Epoch 52/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7263 - val_loss: 0.4421 - val_accuracy: 0.7093\n",
      "Epoch 53/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7231 - val_loss: 0.4363 - val_accuracy: 0.7660\n",
      "Epoch 54/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7373 - val_loss: 0.4343 - val_accuracy: 0.7623\n",
      "Epoch 55/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7427 - val_loss: 0.4419 - val_accuracy: 0.7642\n",
      "Epoch 56/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7545 - val_loss: 0.4298 - val_accuracy: 0.7715\n",
      "Epoch 57/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7286 - val_loss: 0.4332 - val_accuracy: 0.7623\n",
      "Epoch 58/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.7208 - val_loss: 0.4297 - val_accuracy: 0.7642\n",
      "Epoch 59/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7459 - val_loss: 0.4246 - val_accuracy: 0.7788\n",
      "Epoch 60/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7380 - val_loss: 0.4349 - val_accuracy: 0.7623\n",
      "Epoch 61/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7310 - val_loss: 0.4216 - val_accuracy: 0.7843\n",
      "Epoch 62/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7412 - val_loss: 0.4249 - val_accuracy: 0.7843\n",
      "Epoch 63/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7357 - val_loss: 0.4383 - val_accuracy: 0.7148\n",
      "Epoch 64/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7412 - val_loss: 0.4143 - val_accuracy: 0.7824\n",
      "Epoch 65/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7631 - val_loss: 0.4380 - val_accuracy: 0.7642\n",
      "Epoch 66/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7333 - val_loss: 0.4233 - val_accuracy: 0.7788\n",
      "Epoch 67/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7451 - val_loss: 0.4413 - val_accuracy: 0.7623\n",
      "Epoch 68/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7380 - val_loss: 0.4354 - val_accuracy: 0.7569\n",
      "Epoch 69/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7427 - val_loss: 0.4184 - val_accuracy: 0.7733\n",
      "Epoch 70/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7286 - val_loss: 0.4272 - val_accuracy: 0.7623\n",
      "Epoch 71/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7467 - val_loss: 0.4285 - val_accuracy: 0.7057\n",
      "Epoch 72/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7396 - val_loss: 0.4186 - val_accuracy: 0.7934\n",
      "Epoch 73/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7569 - val_loss: 0.4276 - val_accuracy: 0.7697\n",
      "Epoch 74/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7459 - val_loss: 0.4159 - val_accuracy: 0.7824\n",
      "Epoch 75/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7333 - val_loss: 0.4144 - val_accuracy: 0.7824\n",
      "Epoch 76/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7631 - val_loss: 0.4159 - val_accuracy: 0.7843\n",
      "Epoch 77/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7600 - val_loss: 0.4290 - val_accuracy: 0.7733\n",
      "Epoch 78/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7294 - val_loss: 0.4175 - val_accuracy: 0.7843\n",
      "Epoch 79/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7459 - val_loss: 0.4061 - val_accuracy: 0.8172\n",
      "Epoch 80/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7600 - val_loss: 0.4236 - val_accuracy: 0.7934\n",
      "Epoch 81/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7310 - val_loss: 0.4157 - val_accuracy: 0.7751\n",
      "Epoch 82/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7490 - val_loss: 0.4193 - val_accuracy: 0.7733\n",
      "Epoch 83/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7475 - val_loss: 0.4196 - val_accuracy: 0.7697\n",
      "Epoch 84/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7176 - val_loss: 0.4149 - val_accuracy: 0.7697\n",
      "Epoch 85/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7584 - val_loss: 0.4117 - val_accuracy: 0.7824\n",
      "Epoch 86/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7522 - val_loss: 0.4139 - val_accuracy: 0.7751\n",
      "Epoch 87/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7600 - val_loss: 0.4096 - val_accuracy: 0.7971\n",
      "Epoch 88/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7584 - val_loss: 0.4157 - val_accuracy: 0.7788\n",
      "Epoch 89/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7647 - val_loss: 0.4132 - val_accuracy: 0.7733\n",
      "Epoch 90/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7443 - val_loss: 0.4249 - val_accuracy: 0.7751\n",
      "Epoch 91/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7678 - val_loss: 0.4025 - val_accuracy: 0.8007\n",
      "Epoch 92/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7404 - val_loss: 0.4182 - val_accuracy: 0.7715\n",
      "Epoch 93/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7537 - val_loss: 0.4075 - val_accuracy: 0.7989\n",
      "Epoch 94/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7733 - val_loss: 0.3955 - val_accuracy: 0.8154\n",
      "Epoch 95/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7514 - val_loss: 0.4114 - val_accuracy: 0.8135\n",
      "Epoch 96/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7624 - val_loss: 0.4221 - val_accuracy: 0.7788\n",
      "Epoch 97/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7427 - val_loss: 0.3833 - val_accuracy: 0.8336\n",
      "Epoch 98/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7663 - val_loss: 0.3854 - val_accuracy: 0.8391\n",
      "Epoch 99/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7671 - val_loss: 0.3876 - val_accuracy: 0.8428\n",
      "Epoch 100/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7757 - val_loss: 0.3976 - val_accuracy: 0.8117\n",
      "Epoch 101/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7616 - val_loss: 0.3910 - val_accuracy: 0.8446\n",
      "Epoch 102/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7616 - val_loss: 0.3937 - val_accuracy: 0.8172\n",
      "Epoch 103/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7780 - val_loss: 0.3742 - val_accuracy: 0.8647\n",
      "Epoch 104/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7576 - val_loss: 0.3662 - val_accuracy: 0.8574\n",
      "Epoch 105/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7725 - val_loss: 0.4071 - val_accuracy: 0.7879\n",
      "Epoch 106/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7663 - val_loss: 0.3788 - val_accuracy: 0.8391\n",
      "Epoch 107/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7702 - val_loss: 0.3738 - val_accuracy: 0.8483\n",
      "Epoch 108/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7702 - val_loss: 0.3671 - val_accuracy: 0.8592\n",
      "Epoch 109/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7890 - val_loss: 0.3683 - val_accuracy: 0.8611\n",
      "Epoch 110/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7655 - val_loss: 0.3878 - val_accuracy: 0.8062\n",
      "Epoch 111/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7616 - val_loss: 0.3687 - val_accuracy: 0.8574\n",
      "Epoch 112/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7725 - val_loss: 0.3457 - val_accuracy: 0.8812\n",
      "Epoch 113/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7859 - val_loss: 0.3777 - val_accuracy: 0.8501\n",
      "Epoch 114/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7710 - val_loss: 0.3825 - val_accuracy: 0.8373\n",
      "Epoch 115/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7780 - val_loss: 0.3569 - val_accuracy: 0.8629\n",
      "Epoch 116/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7898 - val_loss: 0.3712 - val_accuracy: 0.8592\n",
      "Epoch 117/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7576 - val_loss: 0.3565 - val_accuracy: 0.8720\n",
      "Epoch 118/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7678 - val_loss: 0.3728 - val_accuracy: 0.8611\n",
      "Epoch 119/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7804 - val_loss: 0.3505 - val_accuracy: 0.8611\n",
      "Epoch 120/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7827 - val_loss: 0.3360 - val_accuracy: 0.8812\n",
      "Epoch 121/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7945 - val_loss: 0.3430 - val_accuracy: 0.8812\n",
      "Epoch 122/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7804 - val_loss: 0.3798 - val_accuracy: 0.8227\n",
      "Epoch 123/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7788 - val_loss: 0.3408 - val_accuracy: 0.8647\n",
      "Epoch 124/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8016 - val_loss: 0.3400 - val_accuracy: 0.8848\n",
      "Epoch 125/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8031 - val_loss: 0.3427 - val_accuracy: 0.8757\n",
      "Epoch 126/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7929 - val_loss: 0.3410 - val_accuracy: 0.8921\n",
      "Epoch 127/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.7984 - val_loss: 0.3350 - val_accuracy: 0.8775\n",
      "Epoch 128/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7945 - val_loss: 0.3231 - val_accuracy: 0.8940\n",
      "Epoch 129/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7914 - val_loss: 0.3245 - val_accuracy: 0.8885\n",
      "Epoch 130/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7875 - val_loss: 0.3200 - val_accuracy: 0.8903\n",
      "Epoch 131/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7859 - val_loss: 0.3108 - val_accuracy: 0.8958\n",
      "Epoch 132/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8110 - val_loss: 0.3052 - val_accuracy: 0.9122\n",
      "Epoch 133/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8118 - val_loss: 0.3103 - val_accuracy: 0.9013\n",
      "Epoch 134/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7984 - val_loss: 0.3135 - val_accuracy: 0.8940\n",
      "Epoch 135/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7898 - val_loss: 0.2927 - val_accuracy: 0.9122\n",
      "Epoch 136/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7953 - val_loss: 0.2979 - val_accuracy: 0.9031\n",
      "Epoch 137/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8039 - val_loss: 0.2945 - val_accuracy: 0.9177\n",
      "Epoch 138/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8094 - val_loss: 0.2845 - val_accuracy: 0.9159\n",
      "Epoch 139/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8047 - val_loss: 0.2994 - val_accuracy: 0.9068\n",
      "Epoch 140/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7953 - val_loss: 0.3055 - val_accuracy: 0.9104\n",
      "Epoch 141/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7992 - val_loss: 0.3019 - val_accuracy: 0.9049\n",
      "Epoch 142/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8275 - val_loss: 0.2929 - val_accuracy: 0.8995\n",
      "Epoch 143/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7976 - val_loss: 0.2899 - val_accuracy: 0.9104\n",
      "Epoch 144/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8141 - val_loss: 0.2794 - val_accuracy: 0.9159\n",
      "Epoch 145/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8016 - val_loss: 0.3141 - val_accuracy: 0.8995\n",
      "Epoch 146/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7890 - val_loss: 0.2937 - val_accuracy: 0.9104\n",
      "Epoch 147/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8259 - val_loss: 0.2889 - val_accuracy: 0.9086\n",
      "Epoch 148/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.8071 - val_loss: 0.2886 - val_accuracy: 0.9159\n",
      "Epoch 149/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.2973 - val_accuracy: 0.9104\n",
      "Epoch 150/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8361 - val_loss: 0.3041 - val_accuracy: 0.9013\n",
      "Epoch 151/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.2877 - val_accuracy: 0.9232\n",
      "Epoch 152/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.8118 - val_loss: 0.2990 - val_accuracy: 0.9013\n",
      "Epoch 153/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8102 - val_loss: 0.2929 - val_accuracy: 0.9177\n",
      "Epoch 154/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8173 - val_loss: 0.2954 - val_accuracy: 0.9214\n",
      "Epoch 155/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8157 - val_loss: 0.2835 - val_accuracy: 0.9232\n",
      "Epoch 156/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8220 - val_loss: 0.2854 - val_accuracy: 0.9232\n",
      "Epoch 157/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8094 - val_loss: 0.2902 - val_accuracy: 0.9086\n",
      "Epoch 158/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8086 - val_loss: 0.3126 - val_accuracy: 0.8995\n",
      "Epoch 159/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8110 - val_loss: 0.2751 - val_accuracy: 0.9232\n",
      "Epoch 160/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8086 - val_loss: 0.2902 - val_accuracy: 0.9196\n",
      "Epoch 161/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8306 - val_loss: 0.2747 - val_accuracy: 0.9214\n",
      "Epoch 162/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8243 - val_loss: 0.2754 - val_accuracy: 0.9287\n",
      "Epoch 163/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8180 - val_loss: 0.2817 - val_accuracy: 0.9104\n",
      "Epoch 164/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8212 - val_loss: 0.2726 - val_accuracy: 0.9214\n",
      "Epoch 165/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8267 - val_loss: 0.2822 - val_accuracy: 0.9177\n",
      "Epoch 166/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8094 - val_loss: 0.2857 - val_accuracy: 0.9177\n",
      "Epoch 167/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4051 - accuracy: 0.8400 - val_loss: 0.2599 - val_accuracy: 0.9287\n",
      "Epoch 168/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8220 - val_loss: 0.2749 - val_accuracy: 0.9269\n",
      "Epoch 169/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8086 - val_loss: 0.2506 - val_accuracy: 0.9378\n",
      "Epoch 170/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8243 - val_loss: 0.2938 - val_accuracy: 0.9250\n",
      "Epoch 171/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8369 - val_loss: 0.2784 - val_accuracy: 0.9324\n",
      "Epoch 172/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8235 - val_loss: 0.2675 - val_accuracy: 0.9250\n",
      "Epoch 173/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8180 - val_loss: 0.2963 - val_accuracy: 0.9122\n",
      "Epoch 174/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8290 - val_loss: 0.2811 - val_accuracy: 0.9196\n",
      "Epoch 175/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.8102 - val_loss: 0.2821 - val_accuracy: 0.9049\n",
      "Epoch 176/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8180 - val_loss: 0.2642 - val_accuracy: 0.9214\n",
      "Epoch 177/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8000 - val_loss: 0.2862 - val_accuracy: 0.9196\n",
      "Epoch 178/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8275 - val_loss: 0.2663 - val_accuracy: 0.9196\n",
      "Epoch 179/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8259 - val_loss: 0.2736 - val_accuracy: 0.9269\n",
      "Epoch 180/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8251 - val_loss: 0.2697 - val_accuracy: 0.9250\n",
      "Epoch 181/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.8196 - val_loss: 0.2702 - val_accuracy: 0.9214\n",
      "Epoch 182/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8235 - val_loss: 0.2963 - val_accuracy: 0.9196\n",
      "Epoch 183/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8306 - val_loss: 0.2502 - val_accuracy: 0.9324\n",
      "Epoch 184/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8243 - val_loss: 0.2666 - val_accuracy: 0.9250\n",
      "Epoch 185/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8275 - val_loss: 0.2536 - val_accuracy: 0.9415\n",
      "Epoch 186/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8455 - val_loss: 0.2419 - val_accuracy: 0.9452\n",
      "Epoch 187/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8227 - val_loss: 0.2527 - val_accuracy: 0.9324\n",
      "Epoch 188/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8165 - val_loss: 0.2909 - val_accuracy: 0.9159\n",
      "Epoch 189/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8212 - val_loss: 0.2607 - val_accuracy: 0.9269\n",
      "Epoch 190/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8220 - val_loss: 0.2660 - val_accuracy: 0.9305\n",
      "Epoch 191/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8392 - val_loss: 0.2698 - val_accuracy: 0.9269\n",
      "Epoch 192/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8267 - val_loss: 0.2628 - val_accuracy: 0.9214\n",
      "Epoch 193/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8220 - val_loss: 0.2603 - val_accuracy: 0.9196\n",
      "Epoch 194/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8314 - val_loss: 0.2485 - val_accuracy: 0.9287\n",
      "Epoch 195/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8267 - val_loss: 0.2513 - val_accuracy: 0.9287\n",
      "Epoch 196/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8235 - val_loss: 0.2557 - val_accuracy: 0.9324\n",
      "Epoch 197/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8361 - val_loss: 0.2614 - val_accuracy: 0.9305\n",
      "Epoch 198/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8329 - val_loss: 0.2759 - val_accuracy: 0.9397\n",
      "Epoch 199/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8329 - val_loss: 0.2566 - val_accuracy: 0.9305\n",
      "Epoch 200/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8463 - val_loss: 0.2386 - val_accuracy: 0.9250\n",
      "Epoch 201/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8306 - val_loss: 0.2799 - val_accuracy: 0.9177\n",
      "Epoch 202/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8376 - val_loss: 0.2656 - val_accuracy: 0.9324\n",
      "Epoch 203/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8259 - val_loss: 0.2682 - val_accuracy: 0.9287\n",
      "Epoch 204/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8376 - val_loss: 0.2483 - val_accuracy: 0.9324\n",
      "Epoch 205/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8314 - val_loss: 0.2634 - val_accuracy: 0.9378\n",
      "Epoch 206/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8384 - val_loss: 0.2508 - val_accuracy: 0.9342\n",
      "Epoch 207/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8565 - val_loss: 0.2504 - val_accuracy: 0.9415\n",
      "Epoch 208/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8306 - val_loss: 0.2476 - val_accuracy: 0.9305\n",
      "Epoch 209/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8557 - val_loss: 0.2446 - val_accuracy: 0.9378\n",
      "Epoch 210/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8541 - val_loss: 0.2360 - val_accuracy: 0.9342\n",
      "Epoch 211/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.8502 - val_loss: 0.2385 - val_accuracy: 0.9433\n",
      "Epoch 212/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8714 - val_loss: 0.2298 - val_accuracy: 0.9470\n",
      "Epoch 213/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8416 - val_loss: 0.2422 - val_accuracy: 0.9287\n",
      "Epoch 214/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8471 - val_loss: 0.2541 - val_accuracy: 0.9342\n",
      "Epoch 215/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8549 - val_loss: 0.2634 - val_accuracy: 0.9287\n",
      "Epoch 216/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8659 - val_loss: 0.2543 - val_accuracy: 0.9232\n",
      "Epoch 217/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8549 - val_loss: 0.2419 - val_accuracy: 0.9196\n",
      "Epoch 218/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8447 - val_loss: 0.2422 - val_accuracy: 0.9378\n",
      "Epoch 219/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8620 - val_loss: 0.2283 - val_accuracy: 0.9324\n",
      "Epoch 220/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8533 - val_loss: 0.2355 - val_accuracy: 0.9342\n",
      "Epoch 221/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8478 - val_loss: 0.2213 - val_accuracy: 0.9470\n",
      "Epoch 222/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8549 - val_loss: 0.2254 - val_accuracy: 0.9470\n",
      "Epoch 223/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8612 - val_loss: 0.2366 - val_accuracy: 0.9488\n",
      "Epoch 224/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8729 - val_loss: 0.2270 - val_accuracy: 0.9360\n",
      "Epoch 225/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8659 - val_loss: 0.2269 - val_accuracy: 0.9250\n",
      "Epoch 226/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8675 - val_loss: 0.2571 - val_accuracy: 0.9177\n",
      "Epoch 227/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8792 - val_loss: 0.2208 - val_accuracy: 0.9488\n",
      "Epoch 228/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8690 - val_loss: 0.2333 - val_accuracy: 0.9452\n",
      "Epoch 229/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8643 - val_loss: 0.2266 - val_accuracy: 0.9397\n",
      "Epoch 230/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8541 - val_loss: 0.2248 - val_accuracy: 0.9269\n",
      "Epoch 231/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8800 - val_loss: 0.2186 - val_accuracy: 0.9452\n",
      "Epoch 232/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8549 - val_loss: 0.2500 - val_accuracy: 0.9250\n",
      "Epoch 233/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.8973 - val_loss: 0.2326 - val_accuracy: 0.9324\n",
      "Epoch 234/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8510 - val_loss: 0.2489 - val_accuracy: 0.9324\n",
      "Epoch 235/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8886 - val_loss: 0.2298 - val_accuracy: 0.9324\n",
      "Epoch 236/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8706 - val_loss: 0.2307 - val_accuracy: 0.9397\n",
      "Epoch 237/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8729 - val_loss: 0.2229 - val_accuracy: 0.9378\n",
      "Epoch 238/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8792 - val_loss: 0.2151 - val_accuracy: 0.9415\n",
      "Epoch 239/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8722 - val_loss: 0.2278 - val_accuracy: 0.9324\n",
      "Epoch 240/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8698 - val_loss: 0.2140 - val_accuracy: 0.9378\n",
      "Epoch 241/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8753 - val_loss: 0.2248 - val_accuracy: 0.9324\n",
      "Epoch 242/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8722 - val_loss: 0.2234 - val_accuracy: 0.9415\n",
      "Epoch 243/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8784 - val_loss: 0.2238 - val_accuracy: 0.9452\n",
      "Epoch 244/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8675 - val_loss: 0.2132 - val_accuracy: 0.9378\n",
      "Epoch 245/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8761 - val_loss: 0.2145 - val_accuracy: 0.9488\n",
      "Epoch 246/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8753 - val_loss: 0.2070 - val_accuracy: 0.9433\n",
      "Epoch 247/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8651 - val_loss: 0.2481 - val_accuracy: 0.9433\n",
      "Epoch 248/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8745 - val_loss: 0.2216 - val_accuracy: 0.9342\n",
      "Epoch 249/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3196 - accuracy: 0.8808 - val_loss: 0.2277 - val_accuracy: 0.9378\n",
      "Epoch 250/250\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8816 - val_loss: 0.2346 - val_accuracy: 0.9543\n"
     ]
    }
   ],
   "source": [
    "in_dim=len(df.columns)-1\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim = in_dim, activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(4, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "history=model.fit(X_train_scaled, y_train, epochs = 250, batch_size = 20,validation_split = 0.3,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "44398e05-a6ab-4675-905a-5ad93bc59152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18e04ff5350>]"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],color='green')\n",
    "plt.plot(history.history['val_loss'],color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad2c177-643a-4cf1-a84a-35f10af3b44b",
   "metadata": {},
   "source": [
    "# Obsering Pattern cross validation loss less than training loss\n",
    "### Special Case to be solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "26f50762-700e-4dd4-94c9-80c5e355d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1000us/step - loss: 0.2443 - accuracy: 0.9232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9232456088066101"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check=model.evaluate(X_test_scaled,y_test)\n",
    "check[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "1b38a52b-9d74-4b34-952f-03c5d3ee0d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1422    2\n",
       "2155    3\n",
       "1219    1\n",
       "1264    2\n",
       "429     0\n",
       "       ..\n",
       "583     1\n",
       "1443    2\n",
       "1678    2\n",
       "618     1\n",
       "2249    3\n",
       "Name: Fault, Length: 456, dtype: int64"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic={0:'Inner Race',\n",
    "1:'Normal',\n",
    "2:'Outer Race',\n",
    "3:'Roller Element'}\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "c506acba-df2d-49d9-a0c1-5fee4394b21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 883us/step\n",
      "matched at 0 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 1 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 2 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 3 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 4 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 5 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 6 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 7 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 8 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 9 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 10 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 11 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 12 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 13 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 14 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 15 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 16 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 17 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 18 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 19 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 20 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 21 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 22 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "Failed at 23 actual value is Inner Race predicted value is Roller Element\n",
      "-----\n",
      "matched at 24 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "Failed at 25 actual value is Normal predicted value is Inner Race\n",
      "-----\n",
      "matched at 26 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 27 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 28 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 29 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 30 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 31 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 32 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "Failed at 33 actual value is Normal predicted value is Inner Race\n",
      "-----\n",
      "matched at 34 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 35 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 36 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 37 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 38 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 39 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 40 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 41 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 42 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 43 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 44 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "Failed at 45 actual value is Normal predicted value is Inner Race\n",
      "-----\n",
      "matched at 46 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 47 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 48 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 49 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 50 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 51 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 52 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 53 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 54 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 55 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 56 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 57 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 58 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 59 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 60 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 61 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "Failed at 62 actual value is Normal predicted value is Inner Race\n",
      "-----\n",
      "matched at 63 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 64 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 65 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 66 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 67 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 68 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 69 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 70 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 71 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 72 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 73 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 74 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 75 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 76 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 77 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 78 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 79 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 80 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 81 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 82 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 83 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 84 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 85 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 86 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 87 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 88 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 89 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 90 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 91 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 92 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 93 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 94 actual value is Outer Race predicted value is Outer Race\n",
      "-----\n",
      "matched at 95 actual value is Inner Race predicted value is Inner Race\n",
      "-----\n",
      "matched at 96 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 97 actual value is Normal predicted value is Normal\n",
      "-----\n",
      "matched at 98 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n",
      "matched at 99 actual value is Roller Element predicted value is Roller Element\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(X_test_scaled)\n",
    "actual=y_test\n",
    "for i in range(100):\n",
    "    maxi=0\n",
    "    P=\"\"\n",
    "    A=\"\"\n",
    "    for j in range(4):\n",
    "        maxi=max(maxi,pred[i][j])\n",
    "    for j in range(4):\n",
    "        if(maxi==pred[i][j]):\n",
    "            P=dic[j]\n",
    "            break\n",
    "    A=dic[y_test.iloc[i]]\n",
    "    if(A==P):\n",
    "        print(f'matched at {i} actual value is {A} predicted value is {P}')\n",
    "    else:\n",
    "        print(f'Failed at {i} actual value is {A} predicted value is {P}')\n",
    "    print(\"-----\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "ad59e398-e326-4f31-9aaf-f6b638c5f6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model is 92.32456088066101 at test Data\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy of Model is {100*check[1]} at test Data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
